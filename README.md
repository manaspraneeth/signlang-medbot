# signlang-medbot

AI-powered chatbot that translates ASL (American Sign Language) gestures into medical queries for hearing-impaired users.  
Uses deep learning (MobileNetV2) for gesture recognition and provides real-time text/audio responses to improve healthcare accessibility.

ðŸ‘‰ **Download the pre-trained model** from this link:  
[my_model.keras â€“ Google Drive](https://drive.google.com/file/d/1HFw5d2yWKYgtooXS-V2R4T6iJ0T47Npd/view?usp=sharing)  
Place it in the root directory as: `my_model.keras`


## ðŸ”— Dataset

The model was trained on the ASL Alphabet dataset.

ðŸ‘‰ **Download the dataset** from:  
[ASL Dataset â€“ Google Drive](https://drive.google.com/file/d/1r9JAW_QIjk9OV-wzviOUfUzhywp-mzfs/view?usp=sharing)  
After downloading, extract and place it in the `dataset/` folder in the root directory.

